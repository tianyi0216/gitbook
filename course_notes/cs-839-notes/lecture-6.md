# Lecture 6

## Attention and Transformers

Replace Convolution with "Local Attention"

Convolution: output at each position is inner product of conv kernel with receptive field in input.

Input: $$C \times H \times W$$ -> output: $$C^\prime \times H \times W$$

